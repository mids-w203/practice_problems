---
index: 2
caption: Focus on the First Coin Flip
statement: |
    Suppose that $\\{X_1, X_2, ...\\}$ is a sequence of independent Bernoulli random variables, with common parameter $p$.  For each $n \in \\{1,2,...\\}$, define the estimator $M_n = X_1$. 

    a. Prove that each $M_n$ is an unbiased estimator for $p$.

    b. Prove that $\\{M_n\\}$ is not a consistent estimator for $p$.
---
a. Prove that each $M_n$ is an unbiased estimator for $p$:

 $$E[X] = p, E[M_n] = E[X_1] = E[X] = p$$

 so
 
$$ E[X] - E[M_n ] = p - p = 0$$  

$M_n$ is an unbiased estimator for $p$.

b. Prove that $\\{M_n\\}$ is not a consistent estimator for $p$.

- For an estimator to be consistent, the following condition needs to be satisfied.

$$\lim\limits_{n \to \infty }P(|T_{(n)}-E[X]) < \epsilon = 1 $$

- In our case, the above condition needs to be satisfiyed for the following ranges of epsilon.

$$0 < \epsilon < min(p, 1-p)$$

- We can write the above equation as the following

$$P(-\epsilon + p < M_n < \epsilon + p) = 1 $$

- Now, CDF of Bernoulli distribution, we know CDF is 0 if x <0, 1-p if x is greater than equal to 0 and less than 1, p if x is greater than equal to 1.
- Then, we can write the above equation as shown below.
   
$$
\begin{align}
 P(-\epsilon + p < M_n < \epsilon + p) &= F(\epsilon + p) - F(-\epsilon + p) \\\\
            &= (1-p) - (1-p) \\\\
             &= 0  \\\\
\end{align}
$$

The condition is not satisfied. So, the estimator is inconsistenet. 


