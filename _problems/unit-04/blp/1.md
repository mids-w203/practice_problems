---
index: 1
caption: BLP for a Square
statement: |
    Suppose X and Y have joint density given by,

    $$f(x,y) = \begin{cases} 1, &0 \leq x \leq 1, 0 \leq y \leq 1\\\\\
    0, &otherwise
    \end{cases}
    $$

    1. Prove that the linear predictor $g(x) = 0.5$ fulfills the first population moment condition.

    2. Prove that the linear predictor $g(x) = 0.5$ fulfills the second population moment condition.

    You conclude that $g$ is the BLP.
---
1. We write the equation for error,

$$\epsilon = Y - g(X) = Y - 0.5$$

Taking the expectation,

$$E[\epsilon] = E[Y - 0.5] = E[Y] - 0.5$$

To compute the expectation of $Y$, we first compute the marginal (which will be useful later). We do this by integrating the joint probability. In the range, $0 \le y \le x$, we have

$$
\begin{align}
f_Y(y) &= \int_{x=0}^1 f(x,y) dx \\
&= \int_{x=0}^1 1 dx\\
&= x \vert_{x=0}^1 = 1
\end{align}
$$

Outside of this range, $f_Y(y) = 0$. Since the marginal of $Y$ is uniform on the interval $[0,1]$, its expectation is the midpoint, $E[Y] = .5$.

Plugging into the previous equation, we get $$E[\epsilon] = 0.5 - 0.5 = 0$$, which is the first moment condition.

2. By a similar argument to the one for $Y$, we can compute that $f_X(x) = 1$ for $0 \le x \le 1$ and $f_X(x) = 0$ otherwise, and that $E[X] = .5$.

For (x,y) in the Support of $X$ and $Y$, we can write,

$$f_X(x) f_Y(y) = 1 \cdot 1 = 1 = f(x,y)$$.

So $X$ and $Y$ are independent. this means that $E[XY] = E[X]E[Y]$. 

We are now ready to write down the expression we need:

$$E[\epsilon X] = E[(Y-1/2)X] = E[XY - X/2] = E[XY] - E[X]/2$$ = E[X]E[Y] - E[X]/2 = (0.5)(0.5) - (0.5)/2 = 0$$

which establishes the second moment condition.

